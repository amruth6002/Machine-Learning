# ğŸ“Š ML / DL / AI Math Prep Guide
> A step-by-step, resource-linked roadmap to master the math needed for Machine Learning, Deep Learning, and AI interviews & implementation â€” without overstudying.

---

## ğŸ“ Legend
- ğŸŸ¢ **Core** â€“ Must learn for ML/DL
- ğŸŸ¡ **Useful** â€“ Good to know, sometimes asked
- ğŸ”µ **Applied** â€“ Needed for implementation
- ğŸ”´ **Optional** â€“ Only for research-level AI

---

## **Phase 1 â€“ Probability & Statistics for ML (Weeks 1â€“3)**

| Subtopic | Priority | Resource | Link | Coding Practice |
|----------|----------|----------|------|-----------------|
| Probability rules & conditional probability | ğŸŸ¢ | StatQuest + Stat 110 Ch 1â€“2 | [StatQuest Video](https://youtu.be/UZGgVxRt0f4) Â· [Stat 110 Notes](https://projects.iq.harvard.edu/stat110/home) | Simulate coin tosses & dice |
| Bayes theorem & Naive Bayes | ğŸŸ¢ | StatQuest | [Bayes Theorem](https://youtu.be/HZGCoVF3YvM) | Build Naive Bayes text classifier |
| Expectation, variance, covariance | ğŸŸ¢ | Khan Academy | [Expected Value](https://www.khanacademy.org/math/statistics-probability/probability-library) | Compute E[X], Var(X) from dataset |
| Distributions (Normal, Bernoulli, Multinomial, Uniform) | ğŸŸ¢ | Khan Academy | [Distributions Module](https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data) | Fit distribution to data |
| CLT & Law of Large Numbers | ğŸŸ¡ | Think Stats (Ch 5) | [Free PDF](https://greenteapress.com/wp/think-stats-2e/) | Simulate CLT with sample means |
| Hypothesis testing (t-test, chi-sq) | ğŸŸ¡ | Khan Academy | [Hypothesis Testing](https://www.khanacademy.org/math/statistics-probability/significance-tests) | Compare 2 datasets |

---

## **Phase 2 â€“ Linear Algebra for ML/DL (Weeks 4â€“6)**

| Subtopic | Priority | Resource | Link | Coding Practice |
|----------|----------|----------|------|-----------------|
| Vectors, matrices, transpose | ğŸŸ¢ | 3Blue1Brown Essence of LA #1â€“4 | [YouTube Playlist](https://www.3blue1brown.com/topics/linear-algebra) | Implement matrix multiplication |
| Dot product & projections | ğŸŸ¢ | Khan Academy | [Vectors Module](https://www.khanacademy.org/math/linear-algebra) | Cosine similarity between docs |
| Matrix multiplication & properties | ğŸŸ¢ | 3Blue1Brown #5â€“7 | [YouTube](https://youtu.be/XkY2DOUCWMU) | Implement linear layer forward pass |
| Determinant & inverse | ğŸŸ¡ | Khan Academy | [Matrix Properties](https://www.khanacademy.org/math/linear-algebra/matrix-transformations) | Solve Ax = b |
| Eigenvalues/vectors & SVD | ğŸŸ¢ | 3Blue1Brown #9â€“14 | [YouTube](https://youtu.be/PFDu9oVAE-g) | Implement PCA from scratch |
| Orthogonality & projections | ğŸŸ¢ | Khan Academy | [Orthogonal Module](https://www.khanacademy.org/math/linear-algebra/alternate-bases) | Project vector onto subspace |

---

## **Phase 3 â€“ Calculus & Optimization for ML/DL (Weeks 7â€“9)**

| Subtopic | Priority | Resource | Link | Coding Practice |
|----------|----------|----------|------|-----------------|
| Derivatives & partial derivatives | ğŸŸ¢ | Khan Academy | [Derivatives Module](https://www.khanacademy.org/math/calculus-1) | Differentiate cost functions |
| Chain rule & multivariable derivatives | ğŸŸ¢ | Khan Academy | [Multivariable Calculus](https://www.khanacademy.org/math/multivariable-calculus) | Backprop in 2-layer NN |
| Gradient vectors | ğŸŸ¢ | Khan Academy | [Gradient Module](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives) | Implement gradient descent |
| Hessian matrix & curvature | ğŸŸ¡ | Khan Academy | [Multivariable Section](https://www.khanacademy.org/math/multivariable-calculus) | Visualize loss surface |
| Optimization (SGD, Momentum, Adam) | ğŸ”µ | Andrew Ng ML Course | [Coursera Link](https://www.coursera.org/learn/machine-learning) | Train logistic regression with Adam |

---

## **Phase 4 â€“ ML/DL-Specific Math (Weeks 10â€“12)**

| Subtopic | Priority | Resource | Link | Coding Practice |
|----------|----------|----------|------|-----------------|
| Linear regression (OLS, L1/L2) | ğŸŸ¢ | StatQuest | [Regression Videos](https://youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) | Implement from scratch |
| Logistic regression & sigmoid | ğŸŸ¢ | StatQuest | [Logistic Regression](https://youtu.be/yIYKR4sgzI8) | Implement binary classifier |
| Softmax & cross-entropy | ğŸŸ¢ | PRML (Bishop) Sec 4.3 | [Book PDF](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) | Implement softmax classifier |
| Bias-variance tradeoff | ğŸŸ¢ | StatQuest | [Bias-Variance](https://youtu.be/EuBBz3bI-aA) | Train under/overfit models |
| Activation functions | ğŸŸ¢ | Goodfellow DL Book Ch 6 | [Free PDF](https://www.deeplearningbook.org/) | Compare activations in NN |
| Loss functions (MSE, MAE, CE) | ğŸŸ¢ | Goodfellow DL Book Ch 6 | [Free PDF](https://www.deeplearningbook.org/) | Code custom loss |
| Regularization (L1, L2, dropout) | ğŸŸ¢ | Andrew Ng ML | [Coursera Link](https://www.coursera.org/learn/machine-learning) | Apply in NN |
| Information theory basics (entropy, KL divergence) | ğŸŸ¡ | Victor Lavrenko YouTube | [Playlist](https://youtube.com/playlist?list=PLBv09BD7ez_6k3cPO2pF0u2TIGU9k_F8k) | Compute KL divergence |

---

## ğŸ”„ Review Plan
- **Weekly:** Redo 1 coding exercise from each phase  
- **Biweekly:** Solve 5 ML math interview questions (*Deep Learning Interviews* book)  
- **Monthly:** Implement a model from scratch without frameworks  

---

## ğŸ“š Extra References
- [CS229 Stanford ML Notes](https://cs229.stanford.edu/)  
- [Dive Into Deep Learning](https://d2l.ai/)  
- [Fast.ai Practical Deep Learning](https://course.fast.ai/)  

---
